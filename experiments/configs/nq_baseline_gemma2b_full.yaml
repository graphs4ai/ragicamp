# Natural Questions - Baseline (DirectLLM) with Gemma 2B
# Full evaluation: 100 examples with all metrics

agent:
  type: direct_llm
  name: "gemma_2b_baseline"
  system_prompt: "You are a helpful AI assistant. Answer questions accurately and concisely based on your knowledge."

model:
  type: huggingface
  model_name: "google/gemma-2-2b-it"
  device: "cpu"
  load_in_8bit: true  # Use 8-bit quantization to save memory

dataset:
  name: natural_questions
  split: validation
  num_examples: 5000
  filter_no_answer: true  # Remove questions without explicit answers

# Batch processing for faster evaluation
evaluation:
  batch_size: 8  # Process 8 questions at once (adjust based on GPU memory)

metrics:
  - exact_match
  - f1
  - name: bertscore
    params:
      model_type: "microsoft/deberta-base-mnli"  # Faster variant
  - name: bleurt
    params:
      checkpoint: "BLEURT-20-D3"  # Smaller/faster checkpoint
  - name: llm_judge_qa
    params:
      judgment_type: "binary"

output:
  save_predictions: true
  output_path: "outputs/nq_baseline_gemma2b_full.json"

