# Natural Questions Baseline Evaluation with Batch Processing
# Quick test with 10 examples using batch generation
# ~1-2 minutes on GPU (faster than non-batch version!)

agent:
  type: direct_llm
  name: "gemma_2b_baseline_quick_batch"

model:
  model_name: "google/gemma-2-2b-it"
  device: "cuda"  # Use "cpu" if no GPU available
  load_in_8bit: true  # Reduces memory usage

dataset:
  name: "natural_questions"
  split: "validation"
  num_examples: 10
  filter_no_answer: true  # Only questions with explicit answers

# Batch processing configuration (NEW!)
evaluation:
  batch_size: 4  # Process 4 questions at once (adjust based on GPU memory)

metrics:
  - exact_match
  - f1

output:
  save_predictions: true
  output_path: "outputs/gemma_2b_baseline_quick_batch_results.json"

