# Example: Generate predictions only (no metrics)
# Use this when you want to generate predictions first,
# then compute metrics later (more robust to failures)

agent:
  type: direct_llm
  name: "gemma_2b_baseline_generate"
  system_prompt: "You are a helpful AI assistant. Answer questions accurately and concisely."

model:
  type: huggingface
  model_name: "google/gemma-2-2b-it"
  device: "cuda"
  load_in_8bit: true

dataset:
  name: natural_questions
  split: validation
  num_examples: 100
  filter_no_answer: true

evaluation:
  mode: generate  # Only generate predictions, don't compute metrics
  batch_size: 8   # Process 8 questions at once for speed

metrics:
  # These will be computed later using compute_metrics.py
  - exact_match
  - f1
  - bertscore
  - bleurt
  - llm_judge_qa

output:
  save_predictions: true
  output_path: "outputs/nq_baseline_predictions.json"

