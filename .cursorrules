# RAGiCamp - AI Coding Guidelines

## Project Overview

RAGiCamp is a modular framework for RAG (Retrieval-Augmented Generation) experimentation. It uses **Hydra** for composable configuration and **MLflow** for experiment tracking.

**Tech Stack:** Python 3.9+, PyTorch, HuggingFace, FAISS, Hydra, MLflow, Ragas

---

## Quick Reference

### Running Experiments

```bash
# New Hydra CLI (preferred)
python -m ragicamp.cli.run model=gemma_2b dataset=nq

# With overrides
python -m ragicamp.cli.run model=phi3 dataset=triviaqa evaluation.num_examples=50

# Multi-run sweeps
python -m ragicamp.cli.run -m model=gemma_2b,phi3 dataset=nq,triviaqa
```

### Key Directories

```
conf/                   # Hydra configs (NEW - use this!)
‚îú‚îÄ‚îÄ config.yaml         # Main defaults
‚îú‚îÄ‚îÄ model/              # Model configs
‚îú‚îÄ‚îÄ dataset/            # Dataset configs
‚îú‚îÄ‚îÄ agent/              # Agent configs
‚îú‚îÄ‚îÄ metrics/            # Metric presets
‚îú‚îÄ‚îÄ evaluation/         # Eval settings
‚îî‚îÄ‚îÄ experiment/         # Complete presets

src/ragicamp/
‚îú‚îÄ‚îÄ core/               # Logging, exceptions, constants (NEW)
‚îú‚îÄ‚îÄ cli/                # Hydra CLI runner (NEW)
‚îú‚îÄ‚îÄ agents/             # RAG agents
‚îú‚îÄ‚îÄ models/             # LLM wrappers
‚îú‚îÄ‚îÄ metrics/            # Evaluation metrics
‚îú‚îÄ‚îÄ datasets/           # Dataset loaders
‚îî‚îÄ‚îÄ retrievers/         # Document retrievers

scripts/                # Utility scripts
docs/                   # Documentation
tests/                  # Test suite
```

---

## Architecture Principles

### 1. Hydra Configuration (NEW)

**Always use Hydra configs** for experiments:

```yaml
# conf/config.yaml composes from subdirectories
defaults:
  - model: gemma_2b
  - dataset: nq
  - agent: direct_llm
  - metrics: standard
  - evaluation: quick
```

**Override via CLI:**
```bash
python -m ragicamp.cli.run model=phi3 evaluation.num_examples=100
```

**DON'T** create standalone YAML files in `experiments/configs/` - use `conf/` structure.

### 2. Core Infrastructure (NEW)

**Use structured logging:**
```python
from ragicamp.core.logging import get_logger, LogContext

logger = get_logger(__name__)
logger.info("Processing dataset")

with LogContext(logger, "evaluation"):
    # Logs: [evaluation] Starting...
    results = evaluate()
    # Logs: [evaluation] Completed in 5.2s
```

**Use custom exceptions:**
```python
from ragicamp.core.exceptions import ConfigurationError, ModelError

if not config.model:
    raise ConfigurationError("Model configuration required", field="model")
```

**Use constants (not magic strings):**
```python
from ragicamp.core.constants import AgentType, MetricType

if agent_type == AgentType.DIRECT_LLM:
    ...
```

### 3. Clean Abstractions

- **Base classes** define interfaces via ABC
- **Dependency injection** - agents receive models/retrievers
- **Type safety** - Use dataclasses, not Dict[str, Any]
- **Protocols** for runtime type checking

---

## Code Patterns

### Agent Pattern

```python
from ragicamp.agents.base import RAGAgent, RAGContext, RAGResponse

class MyAgent(RAGAgent):
    def answer(self, query: str, **kwargs) -> RAGResponse:
        context = RAGContext(query=query)
        answer = self.model.generate(query)
        return RAGResponse(answer=answer, context=context)
```

### Metric Pattern

```python
from ragicamp.metrics.base import Metric

class MyMetric(Metric):
    def compute(self, predictions, references) -> Dict[str, float]:
        return {"my_metric": score}  # Always return Dict[str, float]
```

### Hydra Config Usage

```python
import hydra
from omegaconf import DictConfig

@hydra.main(version_base=None, config_path="../../conf", config_name="config")
def main(cfg: DictConfig):
    # Access config values
    model_name = cfg.model.model_name
    num_examples = cfg.evaluation.num_examples
```

---

## DO's and DON'Ts

### Configuration

```python
# ‚úÖ DO - Use Hydra overrides
python -m ragicamp.cli.run model=phi3 dataset=triviaqa

# ‚ùå DON'T - Create new YAML files for each experiment
experiments/configs/nq_phi3_100_examples.yaml  # Bad!
```

### Logging

```python
# ‚úÖ DO - Use structured logging
from ragicamp.core.logging import get_logger
logger = get_logger(__name__)
logger.info("Loaded %d examples", count)

# ‚ùå DON'T - Use print statements
print(f"Loaded {count} examples")  # Bad!
```

### Error Handling

```python
# ‚úÖ DO - Use custom exceptions
from ragicamp.core.exceptions import ModelError
raise ModelError("Failed to load model", model_name=name)

# ‚ùå DON'T - Use bare exceptions
raise Exception("Something went wrong")  # Bad!
```

### Types

```python
# ‚úÖ DO - Use proper types
from ragicamp.retrievers.base import Document
docs: List[Document] = retriever.retrieve(query)

# ‚ùå DON'T - Use dicts
docs: List[Dict[str, Any]] = [{"text": "..."}]  # Bad!
```

---

## File Organization

### Adding New Components

**New agent:** `src/ragicamp/agents/my_agent.py`
**New metric:** `src/ragicamp/metrics/my_metric.py`
**New config:** `conf/model/my_model.yaml` (in appropriate subdir)
**New script:** `scripts/utils/my_script.py`

### Documentation

**‚úÖ Proper locations:**
- Feature guides ‚Üí `docs/guides/`
- Quick reference ‚Üí `CHEATSHEET.md`
- Contributing ‚Üí `CONTRIBUTING.md`

**‚ùå DON'T create:**
- Standalone `.md` files in root
- Scattered README files
- Temporary "IMPROVEMENTS.md" files

---

## Common Tasks

### Add a New Model Config

```yaml
# conf/model/my_model.yaml
model_name: "my-org/my-model"
type: huggingface
device: cuda
load_in_8bit: true
```

### Add a New Experiment Preset

```yaml
# conf/experiment/my_experiment.yaml
defaults:
  - /model: my_model
  - /dataset: nq
  - /agent: fixed_rag
  - /metrics: full
  - /evaluation: standard
```

### Run with the Preset

```bash
python -m ragicamp.cli.run +experiment=my_experiment
```

---

## Testing

```bash
make test              # All tests
make test-coverage     # With coverage
uv run pytest tests/test_metrics.py -v  # Specific file
```

Use fixtures from `tests/conftest.py`:
```python
def test_agent(mock_model, sample_dataset):
    agent = DirectLLMAgent(model=mock_model)
    ...
```

---

## Makefile Commands

```bash
make help              # Show all commands
make test              # Run tests
make format            # Format code
make validate-all-configs  # Validate Hydra configs

# Experiments
make quick-test        # Quick smoke test
make baseline-direct   # DirectLLM baseline
make baseline-rag      # FixedRAG baseline

# Data
make download-nq       # Download Natural Questions
make index-small       # Create small index
```

---

## When Helping Users

1. **Check conf/ first** - New config system
2. **Use core module** - Logging, exceptions, constants
3. **Follow Hydra patterns** - Overrides, not new files
4. **Update proper docs** - `docs/guides/`, not root
5. **Use Makefile** - Add commands for new scripts
6. **Test changes** - At least `make test`
7. **Keep it simple** - Minimal changes needed

---

## Key Files

| File | Purpose |
|------|---------|
| `conf/config.yaml` | Main Hydra config |
| `src/ragicamp/cli/run.py` | Hydra CLI entry point |
| `src/ragicamp/core/` | Logging, exceptions, constants |
| `CHEATSHEET.md` | Quick reference |
| `CONTRIBUTING.md` | How to contribute |
| `docs/guides/HYDRA_CONFIG.md` | Config system docs |
| `Makefile` | All commands |

---

## Project Status

**v0.2.0 Features:**
- ‚úÖ Hydra composable configs
- ‚úÖ MLflow experiment tracking
- ‚úÖ Ragas metric integration
- ‚úÖ Structured logging & exceptions
- ‚úÖ Consolidated documentation
- ‚úÖ Robust CI/CD workflows

**Key Agents:** DirectLLM, FixedRAG, BanditRAG, MDPRAG
**Key Metrics:** EM, F1, BERTScore, BLEURT, Ragas (faithfulness, relevancy)

---

**Remember:** Hydra configs, structured logging, proper types! üöÄ
