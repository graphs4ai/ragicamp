# Gemma 2B Model (8-bit Quantized)
# Balanced memory/quality trade-off

type: huggingface
model_name: "google/gemma-2-2b-it"
device: cuda
load_in_8bit: true
load_in_4bit: false
max_tokens: 256
temperature: 0.7
trust_remote_code: true
