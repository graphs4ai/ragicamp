# Standard Evaluation
# Balanced speed and thoroughness
# ~10-20 minutes for 100 examples
#
# Modes:
#   - both: Generate + evaluate in one pass (default)
#   - generate: Only generate predictions, save to disk (Phase 1)
#   - evaluate: Only compute metrics from saved predictions (Phase 2)
#
# For large runs or unstable environments, use two-phase:
#   python -m ragicamp.cli.run evaluation.mode=generate ...
#   python -m ragicamp.cli.run evaluation.mode=evaluate evaluation.predictions_path=...

mode: both
batch_size: 4
checkpoint_every: 20
resume_from_checkpoint: true
retry_failures: true
