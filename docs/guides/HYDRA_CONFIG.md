# Hydra Configuration System

RAGiCamp uses [Hydra](https://hydra.cc/) for flexible, composable experiment configuration.

## Why Hydra?

**Before (old YAML configs):**
```yaml
# nq_baseline_gemma2b_quick.yaml - 53 lines
# nq_baseline_gemma2b_full.yaml - 53 lines (only 2 values different!)
# nq_fixed_rag_gemma2b.yaml - 68 lines (mostly copy-paste)
```

**After (Hydra):**
```bash
# Same experiments, zero duplication:
python -m ragicamp.cli.run experiment=baseline evaluation=quick
python -m ragicamp.cli.run experiment=baseline evaluation=full
python -m ragicamp.cli.run experiment=rag
```

## ğŸ“ Structure

```
conf/
â”œâ”€â”€ config.yaml              # Default config (can be overridden)
â”œâ”€â”€ model/                   # Model configurations (7 options)
â”‚   â”œâ”€â”€ gemma_2b.yaml       
â”‚   â”œâ”€â”€ gemma_2b_4bit.yaml
â”‚   â”œâ”€â”€ gemma_2b_8bit.yaml
â”‚   â”œâ”€â”€ phi3.yaml
â”‚   â”œâ”€â”€ llama3_8b.yaml
â”‚   â”œâ”€â”€ openai_gpt4.yaml
â”‚   â””â”€â”€ cpu.yaml
â”œâ”€â”€ dataset/                 # Dataset configurations (3 options)
â”‚   â”œâ”€â”€ nq.yaml              # Natural Questions
â”‚   â”œâ”€â”€ triviaqa.yaml
â”‚   â””â”€â”€ hotpotqa.yaml
â”œâ”€â”€ agent/                   # Agent configurations (3 options)
â”‚   â”œâ”€â”€ direct_llm.yaml
â”‚   â”œâ”€â”€ fixed_rag.yaml
â”‚   â””â”€â”€ bandit_rag.yaml
â”œâ”€â”€ retriever/               # Retriever configurations
â”‚   â”œâ”€â”€ dense.yaml
â”‚   â””â”€â”€ sparse.yaml
â”œâ”€â”€ metrics/                 # Metric presets (4 options)
â”‚   â”œâ”€â”€ fast.yaml            # EM + F1 only
â”‚   â”œâ”€â”€ standard.yaml        # + LLM judge
â”‚   â”œâ”€â”€ full.yaml            # All metrics
â”‚   â””â”€â”€ rag.yaml             # RAG-specific (Ragas)
â”œâ”€â”€ evaluation/              # Evaluation settings (5 options)
â”‚   â”œâ”€â”€ quick.yaml           # 10 examples, fast
â”‚   â”œâ”€â”€ standard.yaml        # 100 examples
â”‚   â”œâ”€â”€ full.yaml            # All examples
â”‚   â”œâ”€â”€ generate_only.yaml
â”‚   â””â”€â”€ evaluate_only.yaml
â”œâ”€â”€ judge/                   # LLM judge models
â”‚   â”œâ”€â”€ gpt4_mini.yaml
â”‚   â””â”€â”€ gpt4.yaml
â”œâ”€â”€ mlflow/                  # MLflow tracking
â”‚   â”œâ”€â”€ default.yaml
â”‚   â””â”€â”€ disabled.yaml
â””â”€â”€ experiment/              # Complete experiment presets
    â”œâ”€â”€ baseline.yaml        # DirectLLM baseline
    â”œâ”€â”€ rag.yaml             # RAG experiments
    â”œâ”€â”€ quick_test.yaml      # Quick smoke test
    â””â”€â”€ model_comparison.yaml
```

## ğŸš€ Quick Start

### Run with defaults
```bash
python -m ragicamp.cli.run
```

### Override single parameter
```bash
python -m ragicamp.cli.run model=gemma_2b_4bit
```

### Override multiple parameters
```bash
python -m ragicamp.cli.run model=phi3 dataset=triviaqa evaluation=quick
```

### Override specific values
```bash
python -m ragicamp.cli.run dataset.num_examples=50 model.load_in_4bit=true
```

### Multi-run (parameter sweep)
```bash
python -m ragicamp.cli.run --multirun \
  model=gemma_2b,phi3 \
  agent=direct_llm,fixed_rag \
  dataset.num_examples=10,50,100
```

## ğŸ“ Examples

### Quick test with Gemma 2B
```bash
python -m ragicamp.cli.run \
  model=gemma_2b_4bit \
  dataset=nq \
  evaluation=quick \
  metrics=fast
```

### Full RAG experiment
```bash
python -m ragicamp.cli.run \
  experiment=rag \
  model=gemma_2b \
  dataset=nq \
  evaluation=standard
```

### Compare models (multi-run)
```bash
python -m ragicamp.cli.run --multirun \
  model=gemma_2b,phi3,llama3_8b \
  dataset=nq \
  evaluation=standard
```

### Sweep top_k values
```bash
python -m ragicamp.cli.run --multirun \
  agent=fixed_rag \
  agent.top_k=1,3,5,10 \
  dataset.num_examples=100
```

## ğŸ”§ Config Composition

Hydra composes configs from multiple sources:

```yaml
# config.yaml - defaults that can be overridden
defaults:
  - model: gemma_2b           # Use conf/model/gemma_2b.yaml
  - dataset: nq               # Use conf/dataset/nq.yaml
  - agent: direct_llm         # Use conf/agent/direct_llm.yaml
  - metrics: fast             # Use conf/metrics/fast.yaml
  - evaluation: standard      # Use conf/evaluation/standard.yaml
  - _self_                    # This file's values override defaults

# Additional settings
output:
  save_predictions: true
  dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
```

## ğŸ¯ Benefits

1. **No Duplication** - Define model once, reuse everywhere
2. **Easy Overrides** - Change any param from CLI
3. **Multi-run** - Sweep hyperparameters automatically
4. **Composition** - Mix and match components
5. **Reproducibility** - Hydra saves full config with outputs

---

## ğŸ”„ Migration from Old Configs

Old config files in `experiments/configs/` still work! But new experiments should use Hydra.

| Old Way | New Way |
|---------|---------|
| `nq_baseline_gemma2b_quick.yaml` | `experiment=baseline evaluation=quick` |
| `nq_baseline_gemma2b_full.yaml` | `experiment=baseline evaluation=full` |
| `nq_fixed_rag_gemma2b.yaml` | `experiment=rag` |
| Copy YAML and edit | `model=phi3` override |

---

## ğŸ“Š Combinations Available

With Hydra's composition, you have:

- **7 models** Ã— **3 datasets** Ã— **3 agents** Ã— **4 metric sets** Ã— **5 eval modes** = **1,260 combinations**

All without writing a single new config file!

---

## ğŸ§ª Example Workflows

### Research: Compare Models
```bash
# Run same experiment with 3 different models
python -m ragicamp.cli.run --multirun \
  model=gemma_2b_4bit,phi3,llama3_8b \
  dataset=nq \
  evaluation=standard
```

### Debug: Quick Test
```bash
# Fast smoke test (10 examples, no heavy metrics)
python -m ragicamp.cli.run experiment=quick_test
```

### Ablation: Vary top_k
```bash
# Sweep retrieval parameter
python -m ragicamp.cli.run --multirun \
  experiment=rag \
  agent.top_k=1,3,5,10,20
```

### Cross-Dataset Evaluation
```bash
# Same model on all datasets
python -m ragicamp.cli.run --multirun \
  model=gemma_2b_4bit \
  dataset=nq,triviaqa,hotpotqa
```
