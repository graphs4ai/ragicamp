{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB03: Component Analysis\n",
    "\n",
    "**Question:** Which RAG knobs matter most? Optimal values? Interactions?\n",
    "\n",
    "This notebook analyzes RAG component effects:\n",
    "- Variance decomposition (which factors explain the most performance variance)\n",
    "- Marginal effects of each component\n",
    "- Prompt and top-K deep dives\n",
    "- Interaction effects between components\n",
    "- Optimal configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from analysis_utils import (\n",
    "    load_all_results, setup_plotting, identify_bottlenecks,\n",
    "    compute_marginal_means, plot_component_effects,\n",
    "    plot_interaction_heatmap, find_synergistic_combinations,\n",
    "    weighted_mean_with_ci,\n",
    "    PRIMARY_METRIC, BROKEN_MODELS,\n",
    ")\n",
    "\n",
    "setup_plotting()\n",
    "STUDY_PATH = Path(\"../outputs/smart_retrieval_slm\")\n",
    "\n",
    "df_all = load_all_results(STUDY_PATH)\n",
    "df = df_all[~df_all['model_short'].isin(BROKEN_MODELS)].copy()\n",
    "\n",
    "# Focus on RAG experiments only\n",
    "rag = df[df['exp_type'] == 'rag'].copy()\n",
    "print(f\"RAG experiments: {len(rag)} (from {len(df)} total, {len(df_all)} before broken-model filter)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variance Decomposition\n",
    "\n",
    "The single most important thesis figure: which factors explain the most F1 variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottlenecks = identify_bottlenecks(df, PRIMARY_METRIC)\n",
    "\n",
    "if bottlenecks:\n",
    "    print(\"Variance Explained by Factor (%)\")\n",
    "    print(\"=\" * 50)\n",
    "    for factor, pct in bottlenecks.items():\n",
    "        bar = '#' * int(pct / 2)\n",
    "        print(f\"  {factor:<20s}: {pct:5.1f}%  {bar}\")\n",
    "\n",
    "    # Horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    factors = list(bottlenecks.keys())\n",
    "    values = list(bottlenecks.values())\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(factors)))\n",
    "    ax.barh(factors[::-1], values[::-1], color=colors[::-1], edgecolor='black', linewidth=0.5)\n",
    "    ax.set_xlabel('Variance Explained (%)')\n",
    "    ax.set_title('RAG Component Variance Decomposition')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    for i, v in enumerate(values[::-1]):\n",
    "        ax.text(v + 0.3, i, f'{v:.1f}%', va='center', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Marginal Effects\n",
    "\n",
    "Marginal mean of each factor level, controlling for model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['retriever_type', 'embedding_model', 'reranker', 'prompt',\n",
    "           'query_transform', 'top_k']\n",
    "# Filter to factors present with > 1 level\n",
    "factors = [f for f in factors if f in rag.columns and rag[f].nunique() > 1]\n",
    "\n",
    "n_factors = len(factors)\n",
    "ncols = min(3, n_factors)\n",
    "nrows = (n_factors + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(6 * ncols, 5 * nrows))\n",
    "if n_factors == 1:\n",
    "    axes = np.array([axes])\n",
    "axes = np.atleast_2d(axes)\n",
    "\n",
    "for idx, factor in enumerate(factors):\n",
    "    r, c = divmod(idx, ncols)\n",
    "    ax = axes[r, c]\n",
    "    plot_component_effects(df, factor, PRIMARY_METRIC, ax=ax)\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(n_factors, nrows * ncols):\n",
    "    r, c = divmod(idx, ncols)\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "plt.suptitle('Marginal Effects of RAG Components on F1', y=1.01, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt marginal means with CI\n",
    "prompt_stats = weighted_mean_with_ci(rag, 'prompt', PRIMARY_METRIC)\n",
    "print(\"Prompt Performance (mean F1 with 95% CI):\")\n",
    "display(prompt_stats.round(4))\n",
    "\n",
    "# Prompt x Dataset heatmap\n",
    "prompt_ds = rag.groupby(['prompt', 'dataset'])[PRIMARY_METRIC].mean().unstack()\n",
    "if not prompt_ds.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Bar chart\n",
    "    x = range(len(prompt_stats))\n",
    "    yerr_low = np.maximum(prompt_stats['mean'] - prompt_stats['ci_low'], 0)\n",
    "    yerr_high = np.maximum(prompt_stats['ci_high'] - prompt_stats['mean'], 0)\n",
    "    axes[0].bar(x, prompt_stats['mean'], yerr=[yerr_low, yerr_high],\n",
    "               capsize=4, alpha=0.8, color='steelblue')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(prompt_stats['prompt'], rotation=45, ha='right')\n",
    "    axes[0].set_ylabel('Mean F1')\n",
    "    axes[0].set_title('Prompt Performance')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Heatmap\n",
    "    sns.heatmap(prompt_ds, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "                ax=axes[1])\n",
    "    axes[1].set_title('Prompt x Dataset (Mean F1)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top-K Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'top_k' in rag.columns and rag['top_k'].nunique() > 1:\n",
    "    topk_data = rag.dropna(subset=['top_k', PRIMARY_METRIC])\n",
    "    retriever_types = sorted(topk_data['retriever_type'].dropna().unique())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    for rt in retriever_types:\n",
    "        sub = topk_data[topk_data['retriever_type'] == rt]\n",
    "        means = sub.groupby('top_k')[PRIMARY_METRIC].agg(['mean', 'std', 'count'])\n",
    "        means = means.sort_index()\n",
    "        ci = 1.96 * means['std'] / np.sqrt(means['count'])\n",
    "        ax.plot(means.index, means['mean'], marker='o', label=rt)\n",
    "        ax.fill_between(means.index, means['mean'] - ci, means['mean'] + ci, alpha=0.15)\n",
    "\n",
    "    ax.set_xlabel('Top-K')\n",
    "    ax.set_ylabel('Mean F1')\n",
    "    ax.set_title('F1 vs Top-K by Retriever Type')\n",
    "    ax.legend(title='Retriever')\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Top-K has <= 1 unique value; skipping sensitivity plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaction Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_pairs = [\n",
    "    ('retriever_type', 'reranker'),\n",
    "    ('prompt', 'query_transform'),\n",
    "    ('retriever_type', 'embedding_model'),\n",
    "    ('reranker', 'query_transform'),\n",
    "]\n",
    "# Filter to pairs where both factors have > 1 level\n",
    "interaction_pairs = [(f1, f2) for f1, f2 in interaction_pairs\n",
    "                     if f1 in rag.columns and f2 in rag.columns\n",
    "                     and rag[f1].nunique() > 1 and rag[f2].nunique() > 1]\n",
    "\n",
    "n_pairs = len(interaction_pairs)\n",
    "if n_pairs > 0:\n",
    "    ncols = min(2, n_pairs)\n",
    "    nrows = (n_pairs + ncols - 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(7 * ncols, 5 * nrows))\n",
    "    if n_pairs == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes_flat = np.atleast_1d(axes).flatten()\n",
    "\n",
    "    for idx, (f1, f2) in enumerate(interaction_pairs):\n",
    "        plot_interaction_heatmap(df, f1, f2, PRIMARY_METRIC, ax=axes_flat[idx])\n",
    "\n",
    "    for idx in range(n_pairs, len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "\n",
    "    plt.suptitle('Component Interaction Heatmaps', y=1.01, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough factor pairs with multiple levels for interaction analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synergistic / redundant combos\n",
    "for f1, f2 in interaction_pairs:\n",
    "    combos = find_synergistic_combinations(df, f1, f2, PRIMARY_METRIC)\n",
    "    if combos:\n",
    "        combo_df = pd.DataFrame(combos)\n",
    "        syn = combo_df[combo_df['synergy'] == 'Synergistic']\n",
    "        red = combo_df[combo_df['synergy'] == 'Redundant']\n",
    "        print(f\"\\n{f1} x {f2}:\")\n",
    "        if len(syn) > 0:\n",
    "            print(f\"  Synergistic ({len(syn)}):\")\n",
    "            for _, r in syn.head(3).iterrows():\n",
    "                print(f\"    {r[f1]} + {r[f2]}: interaction = +{r['interaction_effect']:.4f}\")\n",
    "        if len(red) > 0:\n",
    "            print(f\"  Redundant ({len(red)}):\")\n",
    "            for _, r in red.head(3).iterrows():\n",
    "                print(f\"    {r[f1]} + {r[f2]}: interaction = {r['interaction_effect']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimal Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_cols = ['retriever_type', 'embedding_model', 'reranker', 'prompt',\n",
    "               'query_transform', 'top_k', 'agent_type']\n",
    "config_cols = [c for c in config_cols if c in rag.columns]\n",
    "\n",
    "# Best config per dataset\n",
    "print(\"Best Configuration per Dataset:\")\n",
    "print(\"=\" * 60)\n",
    "for ds in sorted(rag['dataset'].unique()):\n",
    "    ds_df = rag[rag['dataset'] == ds]\n",
    "    if ds_df[PRIMARY_METRIC].notna().sum() == 0:\n",
    "        continue\n",
    "    best_idx = ds_df[PRIMARY_METRIC].idxmax()\n",
    "    best = ds_df.loc[best_idx]\n",
    "    print(f\"\\n  {ds} (F1={best[PRIMARY_METRIC]:.4f}):\")\n",
    "    for c in config_cols:\n",
    "        print(f\"    {c:<20s}: {best.get(c, 'n/a')}\")\n",
    "\n",
    "# Best config per model\n",
    "print(\"\\n\\nBest Configuration per Model:\")\n",
    "print(\"=\" * 60)\n",
    "for model in sorted(rag['model_short'].unique()):\n",
    "    m_df = rag[rag['model_short'] == model]\n",
    "    if m_df[PRIMARY_METRIC].notna().sum() == 0:\n",
    "        continue\n",
    "    best_idx = m_df[PRIMARY_METRIC].idxmax()\n",
    "    best = m_df.loc[best_idx]\n",
    "    print(f\"\\n  {model} (F1={best[PRIMARY_METRIC]:.4f}):\")\n",
    "    for c in config_cols:\n",
    "        print(f\"    {c:<20s}: {best.get(c, 'n/a')}\")\n",
    "\n",
    "# \"Universal recipe\" â€” most common values in top-10% of experiments\n",
    "top_pct = rag.nlargest(max(1, len(rag) // 10), PRIMARY_METRIC)\n",
    "print(\"\\n\\nUniversal Recipe (mode of top-10% experiments):\")\n",
    "print(\"=\" * 60)\n",
    "for c in config_cols:\n",
    "    if c in top_pct.columns:\n",
    "        mode = top_pct[c].mode()\n",
    "        print(f\"  {c:<20s}: {mode.iloc[0] if len(mode) > 0 else 'n/a'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "Key takeaways:\n",
    "- Which factor explains the most variance\n",
    "- Best prompt strategy\n",
    "- Optimal top-K range\n",
    "- Synergistic and redundant combinations\n",
    "- Universal vs dataset-specific configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
