{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB02: RAG vs Direct\n",
    "\n",
    "**Question:** Does retrieval help? When? By how much?\n",
    "\n",
    "This notebook compares RAG-augmented configurations against direct (no-retrieval) baselines:\n",
    "- Overall effect size\n",
    "- Distribution of RAG benefit (helps / hurts / neutral)\n",
    "- RAG uplift by model tier and dataset\n",
    "- Success factors for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from analysis_utils import (\n",
    "    load_all_results, setup_plotting, effect_size,\n",
    "    compare_best_rag_vs_direct, analyze_rag_benefit_distribution,\n",
    "    identify_rag_success_factors, plot_rag_benefit_distribution,\n",
    "    PRIMARY_METRIC, MODEL_PARAMS, MODEL_TIER, BROKEN_MODELS,\n",
    ")\n",
    "\n",
    "setup_plotting()\n",
    "STUDY_PATH = Path(\"../outputs/smart_retrieval_slm\")\n",
    "\n",
    "df_all = load_all_results(STUDY_PATH)\n",
    "df = df_all[~df_all['model_short'].isin(BROKEN_MODELS)].copy()\n",
    "print(f\"Loaded {len(df_all)} total, {len(df)} after removing broken models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overall RAG vs Direct Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Per-dataset effect sizes, then combined\nprint(\"Overall RAG vs Direct (dataset-stratified)\")\nprint(\"=\" * 60)\n\ndatasets = sorted(df['dataset'].unique())\nper_ds_results = []\n\nfor ds in datasets:\n    d_vals = df.loc[(df['exp_type'] == 'direct') & (df['dataset'] == ds), PRIMARY_METRIC].dropna().values\n    r_vals = df.loc[(df['exp_type'] == 'rag') & (df['dataset'] == ds), PRIMARY_METRIC].dropna().values\n    if len(d_vals) >= 2 and len(r_vals) >= 2:\n        d_es, p, interp_ds = effect_size(d_vals, r_vals)\n        per_ds_results.append({\n            'dataset': ds, 'direct_mean': np.mean(d_vals), 'rag_mean': np.mean(r_vals),\n            'n_direct': len(d_vals), 'n_rag': len(r_vals),\n            'cohens_d': d_es, 'p_value': p, 'interpretation': interp_ds,\n        })\n        print(f\"  {ds}:\")\n        print(f\"    Direct: mean={np.mean(d_vals):.4f}, n={len(d_vals)}\")\n        print(f\"    RAG:    mean={np.mean(r_vals):.4f}, n={len(r_vals)}\")\n        print(f\"    Cohen's d = {d_es:.3f} ({interp_ds}), p = {p:.2e}\")\n\n# Combined: average per-dataset means (stratified)\nif per_ds_results:\n    combined_direct = np.mean([r['direct_mean'] for r in per_ds_results])\n    combined_rag = np.mean([r['rag_mean'] for r in per_ds_results])\n    combined_d = np.mean([r['cohens_d'] for r in per_ds_results])\n    print(f\"\\n  Combined (stratified mean across {len(per_ds_results)} datasets):\")\n    print(f\"    Direct: mean={combined_direct:.4f}\")\n    print(f\"    RAG:    mean={combined_rag:.4f}\")\n    print(f\"    Mean Cohen's d = {combined_d:.3f}\")\n\n    # Store for summary cell\n    d = combined_d\n    interp = 'large' if abs(d) >= 0.8 else 'medium' if abs(d) >= 0.5 else 'small' if abs(d) >= 0.2 else 'negligible'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-RAG vs Direct per model+dataset\n",
    "comparison = compare_best_rag_vs_direct(df, PRIMARY_METRIC, top_k=3)\n",
    "print(\"Best-3 RAG vs Direct Baseline (per model x dataset):\")\n",
    "display(comparison.round(4))\n",
    "\n",
    "# Grouped bar chart\n",
    "if 'model_short' in comparison.columns and 'dataset' in comparison.columns:\n",
    "    models = sorted(comparison['model_short'].unique())\n",
    "    datasets = sorted(comparison['dataset'].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(datasets), figsize=(6 * len(datasets), 5), sharey=True)\n",
    "    if len(datasets) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, ds in zip(axes, datasets):\n",
    "        sub = comparison[comparison['dataset'] == ds].sort_values('model_short')\n",
    "        x = np.arange(len(sub))\n",
    "        w = 0.35\n",
    "        ax.bar(x - w/2, sub['direct_mean'], w, label='Direct', color='steelblue', alpha=0.8)\n",
    "        ax.bar(x + w/2, sub['top_rag_mean'], w, label='Best RAG', color='coral', alpha=0.8)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(sub['model_short'], rotation=30, ha='right')\n",
    "        ax.set_title(ds)\n",
    "        ax.set_ylabel('F1' if ax == axes[0] else '')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Direct vs Best-3 RAG by Model and Dataset', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Benefit Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit = analyze_rag_benefit_distribution(df, PRIMARY_METRIC)\n",
    "\n",
    "if benefit:\n",
    "    print(\"RAG Benefit Distribution\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  Helps:   {benefit['n_helps']:>4d} ({benefit['pct_helps']:.1f}%)\")\n",
    "    print(f\"  Hurts:   {benefit['n_hurts']:>4d} ({benefit['pct_hurts']:.1f}%)\")\n",
    "    print(f\"  Neutral: {benefit['n_neutral']:>4d}\")\n",
    "    print(f\"  Mean uplift when helps:  {benefit['mean_benefit_when_helps']:.4f}\")\n",
    "    print(f\"  Mean loss when hurts:    {benefit['mean_hurt_when_hurts']:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plot_rag_benefit_distribution(benefit, ax=axes[0])\n",
    "\n",
    "    # Pie chart\n",
    "    sizes = [benefit['n_helps'], benefit['n_hurts'], benefit['n_neutral']]\n",
    "    labels = ['Helps', 'Hurts', 'Neutral']\n",
    "    colors_pie = ['#66bb6a', '#ef5350', '#bdbdbd']\n",
    "    axes[1].pie(sizes, labels=labels, colors=colors_pie, autopct='%1.0f%%',\n",
    "               startangle=90, textprops={'fontsize': 12})\n",
    "    axes[1].set_title('RAG Outcome Distribution')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of RAG benefit by model\n",
    "if benefit:\n",
    "    rag_df = benefit['rag_df']\n",
    "    models = sorted(rag_df['model_short'].unique())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    data_by_model = [rag_df[rag_df['model_short'] == m]['rag_benefit'].dropna().values\n",
    "                     for m in models]\n",
    "    bp = ax.boxplot(data_by_model, labels=models, patch_artist=True)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', linewidth=1, label='Break-even')\n",
    "    ax.set_ylabel('RAG Benefit (F1 delta)')\n",
    "    ax.set_title('RAG Benefit Distribution by Model')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG Uplift by Model Tier\n",
    "\n",
    "Does RAG help weaker models more? Scatter: x = direct baseline F1, y = RAG uplift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute per-model direct baseline and best-RAG (dataset-stratified)\ndirect_df = df[df['exp_type'] == 'direct']\nrag_df = df[df['exp_type'] == 'rag']\n\n# Stratified: per-(model, dataset) means, then average across datasets\nmodel_direct_strat = (\n    direct_df.groupby(['model_short', 'dataset'])[PRIMARY_METRIC].mean()\n    .groupby('model_short').mean()\n)\nmodel_best_rag_strat = (\n    rag_df.groupby(['model_short', 'dataset'])[PRIMARY_METRIC].max()\n    .groupby('model_short').mean()\n)\n\nscatter_data = pd.DataFrame({\n    'direct_f1': model_direct_strat,\n    'best_rag_f1': model_best_rag_strat,\n}).dropna()\nscatter_data['rag_uplift'] = scatter_data['best_rag_f1'] - scatter_data['direct_f1']\nscatter_data['tier'] = scatter_data.index.map(lambda m: MODEL_TIER.get(m, 'unknown'))\nscatter_data['params_b'] = scatter_data.index.map(lambda m: MODEL_PARAMS.get(m, np.nan))\n\ntier_colors = {'tiny': '#ef5350', 'small': '#ffa726', 'medium': '#66bb6a'}\n\nfig, ax = plt.subplots(figsize=(10, 6))\nfor tier, color in tier_colors.items():\n    sub = scatter_data[scatter_data['tier'] == tier]\n    ax.scatter(sub['direct_f1'], sub['rag_uplift'], c=color, s=120,\n              label=tier.capitalize(), edgecolors='black', zorder=3)\n    for model, row in sub.iterrows():\n        ax.annotate(model, (row['direct_f1'], row['rag_uplift']),\n                    textcoords='offset points', xytext=(8, 4), fontsize=9)\n\nax.axhline(y=0, color='grey', linestyle='--', alpha=0.5)\nax.set_xlabel('Direct Baseline F1 (dataset-stratified)')\nax.set_ylabel('Best-RAG Uplift (F1 delta, dataset-stratified)')\nax.set_title('RAG Uplift vs Direct Baseline by Model Tier (Dataset-Stratified)')\nax.legend(title='Tier')\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\ndisplay(scatter_data.round(4))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG Benefit by Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-dataset effect sizes (direct vs all RAG)\n",
    "datasets = sorted(df['dataset'].unique())\n",
    "ds_effects = []\n",
    "for ds in datasets:\n",
    "    d_vals = df.loc[(df['exp_type'] == 'direct') & (df['dataset'] == ds), PRIMARY_METRIC].dropna().values\n",
    "    r_vals = df.loc[(df['exp_type'] == 'rag') & (df['dataset'] == ds), PRIMARY_METRIC].dropna().values\n",
    "    if len(d_vals) >= 2 and len(r_vals) >= 2:\n",
    "        d, pval, interp = effect_size(d_vals, r_vals)\n",
    "        ds_effects.append({\n",
    "            'dataset': ds, 'direct_mean': np.mean(d_vals), 'rag_mean': np.mean(r_vals),\n",
    "            'cohens_d': d, 'p_value': pval, 'interpretation': interp,\n",
    "        })\n",
    "\n",
    "ds_effect_df = pd.DataFrame(ds_effects)\n",
    "display(ds_effect_df.round(4))\n",
    "\n",
    "# Grouped bars\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "x = np.arange(len(ds_effect_df))\n",
    "w = 0.35\n",
    "ax.bar(x - w/2, ds_effect_df['direct_mean'], w, label='Direct', color='steelblue', alpha=0.8)\n",
    "ax.bar(x + w/2, ds_effect_df['rag_mean'], w, label='RAG (mean)', color='coral', alpha=0.8)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(ds_effect_df['dataset'])\n",
    "ax.set_ylabel('F1')\n",
    "ax.set_title('Direct vs RAG by Dataset')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Success Factors for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_factors = identify_rag_success_factors(df, PRIMARY_METRIC)\n",
    "\n",
    "if success_factors:\n",
    "    for factor, table in success_factors.items():\n",
    "        if table.empty:\n",
    "            continue\n",
    "        print(f\"\\n{factor}:\")\n",
    "        display(table.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "Key takeaways:\n",
    "- Overall RAG vs Direct effect size and significance\n",
    "- What fraction of RAG configs help vs hurt\n",
    "- Which model tiers benefit most from RAG\n",
    "- Dataset-specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if benefit:\n",
    "    print(\"RAG vs DIRECT SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Overall Cohen's d:    {d:.3f} ({interp})\")\n",
    "    print(f\"RAG helps in:         {benefit['pct_helps']:.0f}% of configurations\")\n",
    "    print(f\"Best RAG uplift:      {benefit['best_rag_benefit']:.4f}\")\n",
    "    print(f\"Worst RAG penalty:    {benefit['worst_rag_benefit']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}