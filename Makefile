# RAGiCamp Makefile
# Run `make help` for available commands

.PHONY: help install setup test lint format clean

# ============================================================================
# HELP
# ============================================================================

help:
	@echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
	@echo "‚ïë                      RAGiCamp Commands                            ‚ïë"
	@echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
	@echo ""
	@echo "üì¶ SETUP"
	@echo "  make install          Install dependencies"
	@echo "  make setup            Full setup (install + verify)"
	@echo ""
	@echo "üöÄ EXPERIMENTS (Hydra - RECOMMENDED)"
	@echo "  make quick-test       Quick smoke test (10 examples)"
	@echo "  make baseline         DirectLLM baseline evaluation"
	@echo "  make rag              RAG evaluation with retrieval"
	@echo "  make run ARGS='...'   Run with custom Hydra args"
	@echo ""
	@echo "üìä BASELINE STUDY (Systematic experiments)"
	@echo "  make baseline-study-test    Quick test (verify setup)"
	@echo "  make baseline-study-direct  Run DirectLLM experiments"
	@echo "  make baseline-study-rag     Run RAG experiments"
	@echo "  make baseline-study-full    Run complete study"
	@echo "  make sweep-prompts          Compare prompt styles"
	@echo "  make sweep-topk             Compare top_k values"
	@echo "  make sweep-datasets         Compare datasets"
	@echo "  make sweep-models           Compare models"
	@echo ""
	@echo "üìö DATA"
	@echo "  make download-all     Download all datasets"
	@echo "  make index            Index corpus (small, for testing)"
	@echo "  make index-full       Index full Wikipedia corpus"
	@echo "  make info             Show data/artifacts info"
	@echo ""
	@echo "üìä ANALYSIS"
	@echo "  make compare          Compare experiment results"
	@echo "  make report           Generate evaluation report"
	@echo ""
	@echo "üß™ TESTING"
	@echo "  make test             Run all tests"
	@echo "  make test-fast        Run fast tests only"
	@echo ""
	@echo "üîß DEVELOPMENT"
	@echo "  make lint             Run linters"
	@echo "  make format           Format code"
	@echo "  make clean            Clean generated files"
	@echo ""
	@echo "üí° QUICK START"
	@echo "  1. make setup         (first time)"
	@echo "  2. make quick-test    (verify everything works)"
	@echo "  3. make baseline      (run evaluation)"
	@echo ""
	@echo "üìñ See CHEATSHEET.md for more examples"
	@echo ""

# ============================================================================
# SETUP
# ============================================================================

install:
	@echo "üì¶ Installing dependencies..."
	uv sync

install-dev:
	@echo "üì¶ Installing with dev tools..."
	uv sync --extra dev

install-all:
	@echo "üì¶ Installing all dependencies..."
	uv sync --extra dev --extra viz

verify:
	@echo "üîç Verifying installation..."
	@uv run python -c "import torch; print('‚úì PyTorch:', torch.__version__)"
	@uv run python -c "import transformers; print('‚úì Transformers:', transformers.__version__)"
	@uv run python -c "import hydra; print('‚úì Hydra:', hydra.__version__)"
	@uv run python -c "from ragicamp.core import get_logger; print('‚úì RAGiCamp core: OK')"
	@echo ""
	@echo "‚úÖ All dependencies installed correctly!"

setup: install verify
	@echo ""
	@echo "‚úÖ Setup complete! Run: make quick-test"

# ============================================================================
# EXPERIMENTS (Hydra-powered)
# ============================================================================

# Quick smoke test (10 examples, fast metrics)
quick-test:
	@echo "üß™ Running quick test..."
	uv run python -m ragicamp.cli.run experiment=quick_test

# Baseline evaluation (DirectLLM, no retrieval)
baseline:
	@echo "üöÄ Running baseline evaluation..."
	uv run python -m ragicamp.cli.run experiment=baseline

# RAG evaluation (with retrieval)
rag:
	@echo "üîç Running RAG evaluation..."
	@if [ ! -d artifacts/retrievers ]; then \
		echo "‚ö†Ô∏è  No index found. Run 'make index' first."; \
		exit 1; \
	fi
	uv run python -m ragicamp.cli.run experiment=rag

# Compare models (multi-run)
compare-models:
	@echo "üìä Comparing models..."
	uv run python -m ragicamp.cli.run --multirun \
		model=gemma_2b_4bit,phi3 \
		experiment=baseline \
		evaluation=quick

# Custom run with args
run:
	uv run python -m ragicamp.cli.run $(ARGS)

# Show config without running
show-config:
	uv run python -m ragicamp.cli.run --cfg job $(ARGS)

# ============================================================================
# BASELINE STUDY (Systematic experiments)
# ============================================================================

# Quick test - verify everything works
baseline-study-test:
	@echo "üß™ Running baseline study quick test..."
	uv run python scripts/experiments/run_baseline_study.py --quick

# DirectLLM experiments only (faster, no index needed)
baseline-study-direct:
	@echo "üöÄ Running DirectLLM baseline study..."
	uv run python scripts/experiments/run_baseline_study.py --direct-only

# Two-phase baseline: Generate predictions only (Phase 1)
# Saves predictions to disk, no metrics. Safe for unstable environments.
baseline-generate:
	@echo "üöÄ Phase 1: Generating predictions..."
	uv run python -m ragicamp.cli.run \
		experiment=baseline_study_direct \
		evaluation.mode=generate

# Two-phase baseline: Compute metrics only (Phase 2)
# Requires predictions from Phase 1. Pass PREDS_PATH=path/to/predictions.json
baseline-evaluate:
	@echo "üìä Phase 2: Computing metrics..."
	@if [ -z "$(PREDS_PATH)" ]; then \
		echo "‚ùå Error: PREDS_PATH not set. Usage: make baseline-evaluate PREDS_PATH=outputs/.../predictions_raw.json"; \
		exit 1; \
	fi
	uv run python -m ragicamp.cli.run \
		experiment=baseline_study_direct \
		evaluation.mode=evaluate \
		evaluation.predictions_path=$(PREDS_PATH)

# RAG experiments only (needs index)
baseline-study-rag:
	@echo "üîç Running RAG baseline study..."
	uv run python scripts/experiments/run_baseline_study.py --rag-only

# Full baseline study (DirectLLM + RAG)
baseline-study-full:
	@echo "üìä Running full baseline study..."
	uv run python scripts/experiments/run_baseline_study.py --full

# Dry run - show what would be executed
baseline-study-preview:
	@echo "üìã Preview of baseline study commands:"
	uv run python scripts/experiments/run_baseline_study.py --full --dry-run

# Sweep: Compare prompt styles
sweep-prompts:
	@echo "üìù Sweeping prompt styles..."
	uv run python -m ragicamp.cli.run --multirun \
		experiment=baseline_study_direct \
		prompt=concise,sentence,explained \
		evaluation=quick

# Sweep: Compare top_k values
sweep-topk:
	@echo "üîÑ Sweeping top_k values..."
	uv run python -m ragicamp.cli.run --multirun \
		experiment=baseline_study_rag \
		agent.top_k=1,3,5,10 \
		evaluation=quick

# Sweep: Compare datasets
sweep-datasets:
	@echo "üìö Sweeping datasets..."
	uv run python -m ragicamp.cli.run --multirun \
		experiment=baseline_study_direct \
		dataset=nq,triviaqa,hotpotqa \
		evaluation=quick

# Sweep: Compare models
sweep-models:
	@echo "ü§ñ Sweeping models..."
	uv run python -m ragicamp.cli.run --multirun \
		experiment=baseline_study_direct \
		model=gemma_2b_4bit,phi3 \
		evaluation=quick

# ============================================================================
# LEGACY EXPERIMENTS (old YAML configs - for compatibility)
# ============================================================================

eval-baseline-quick:
	@echo "üöÄ Running baseline (legacy config)..."
	uv run python experiments/scripts/run_experiment.py \
		--config experiments/configs/nq_baseline_gemma2b_quick.yaml

eval-baseline-full:
	@echo "üöÄ Running full baseline (legacy config)..."
	uv run python experiments/scripts/run_experiment.py \
		--config experiments/configs/nq_baseline_gemma2b_full.yaml

eval-rag-legacy:
	@echo "üîç Running RAG (legacy config)..."
	uv run python experiments/scripts/run_experiment.py \
		--config experiments/configs/nq_fixed_rag_gemma2b.yaml

# ============================================================================
# DATA PREPARATION
# ============================================================================

# Download datasets
download-nq:
	uv run python scripts/data/download.py --dataset nq

download-triviaqa:
	uv run python scripts/data/download.py --dataset triviaqa

download-hotpotqa:
	uv run python scripts/data/download.py --dataset hotpotqa

download-all:
	@echo "üìö Downloading all datasets..."
	uv run python scripts/data/download.py --all

# Index corpus
index:
	@echo "üìö Indexing corpus (small, for testing)..."
	uv run python scripts/data/index.py --preset small

index-full:
	@echo "üìö Indexing full corpus (this takes a while)..."
	uv run python scripts/data/index.py --preset full

index-test:
	@echo "üìö Indexing tiny corpus (for quick tests)..."
	uv run python scripts/data/index.py --preset test

# Show info
info:
	@uv run python scripts/data/info.py

list-datasets:
	@uv run python scripts/data/info.py --datasets

list-artifacts:
	@uv run python scripts/data/info.py --artifacts

# ============================================================================
# ANALYSIS
# ============================================================================

compare:
	@echo "üìä Comparing experiments..."
	@uv run python scripts/eval/compare.py outputs/

# Compare baseline study results with visualization
compare-baseline:
	@echo "üìä Comparing baseline study results..."
	@uv run python scripts/analysis/compare_baseline.py outputs/

# Compare and export to CSV
compare-csv:
	@echo "üìä Exporting results to CSV..."
	@uv run python scripts/analysis/compare_baseline.py outputs/ --csv outputs/comparison.csv

report:
	@echo "üìù Generating report..."
	@uv run python scripts/eval/report.py outputs/ --format markdown

report-html:
	@echo "üìù Generating HTML report..."
	@uv run python scripts/eval/report.py outputs/ --format html

# ============================================================================
# TESTING
# ============================================================================

test:
	@echo "üß™ Running all tests..."
	uv run pytest tests/ -v

test-fast:
	@echo "‚ö° Running fast tests..."
	uv run pytest tests/ -v -m "not slow"

test-coverage:
	@echo "üìä Running tests with coverage..."
	uv run pytest tests/ --cov=src/ragicamp --cov-report=html --cov-report=term
	@echo "Coverage report: htmlcov/index.html"

test-core:
	uv run pytest tests/test_config.py tests/test_factory.py tests/test_agents.py -v

# ============================================================================
# DEVELOPMENT
# ============================================================================

lint:
	@echo "üîç Running linters..."
	@uv run flake8 src/ tests/ --max-line-length=100 || true
	@uv run mypy src/ragicamp --ignore-missing-imports || true

format:
	@echo "‚ú® Formatting code..."
	uv run black src/ tests/ scripts/ --line-length 100
	uv run isort src/ tests/ scripts/ --profile black
	@echo "‚úÖ Done!"

clean:
	@echo "üßπ Cleaning..."
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete
	rm -rf .pytest_cache .mypy_cache htmlcov/ dist/ build/ *.egg-info
	@echo "‚úÖ Cleaned!"

clean-outputs:
	@echo "üßπ Cleaning outputs..."
	rm -rf outputs/*.json outputs/*/
	@echo "‚úÖ Outputs cleaned!"

clean-artifacts:
	@echo "üßπ Cleaning artifacts..."
	rm -rf artifacts/
	@echo "‚úÖ Artifacts cleaned!"

clean-all: clean clean-outputs
	@echo "‚úÖ All cleaned!"

# ============================================================================
# CONFIGURATION
# ============================================================================

validate-config:
	uv run python scripts/utils/validate_config.py $(CONFIG)

validate-all-configs:
	@echo "üîç Validating all configs..."
	@uv run python scripts/utils/validate_config.py experiments/configs/*.yaml
	@uv run python scripts/utils/validate_config.py conf/experiment/*.yaml

# ============================================================================
# MLFLOW
# ============================================================================

mlflow-ui:
	@echo "üîç Starting MLflow UI..."
	@echo "Open http://localhost:5000 in your browser"
	uv run mlflow ui --backend-store-uri ./mlruns

# ============================================================================
# SHORTCUTS
# ============================================================================

# Aliases for convenience
s: setup
t: test
q: quick-test
b: baseline
r: rag
c: compare
i: info
